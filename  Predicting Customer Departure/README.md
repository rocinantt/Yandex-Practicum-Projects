# Проект: Прогнозирование оттока клиента

## Описание проекта
Проект по прогнозированию оттока клиентов из банка "Бета-Банк". Цель - предсказать, уйдет ли клиент из банка в ближайшее время или нет с помощью модели машинного обучения. Мы стремимся минимизировать отток клиентов, так как сохранение текущих клиентов банка является более дешевым, чем привлечение новых.

## Необходимые библиотеки
- pandas
- matplotlib
- seaborn
- numpy
- scikit-learn
- imbalanced-learn

## Сфера деятельности
Банковская сфера, бизнес, инвестиции, кредитование.

## Используемый стек
Matplotlib, Pandas, Scikit-learn, Seaborn, Numpy.

## Цель проекта
Предоставить заказчику лучшее решение из возможных по прогнозированию оттока клиентов. Наш бенчмарк - достижение значения F1-метрики не менее 0.59.

## Структура проекта
1. **Подготовка данных**: В этом разделе мы проводим предобработку данных, включая обработку пропусков, проверку на дубликаты, кодирование категориальных переменных и разделение данных на обучающую, валидационную и тестовую выборки.
2. **Исследование задачи**: Мы исследуем задачу, сравнивая результаты разных моделей машинного обучения и подбирая оптимальные гиперпараметры с помощью случайного поиска и поиска по сетке.
3. **Улучшение качества модели, учитывая дисбаланс классов**: Мы применяем различные методы борьбы с дисбалансом классов и подбираем оптимальные гиперпараметры для каждого из них.
4. **Тестирование модели**: Мы объединяем обучающую и валидационную выборки, обучаем на них модели и тестируем на тестовой выборке, сравнивая результаты разных методов.

## Результаты и выводы
В рамках проекта были проведены анализ данных, построение и валидация моделей прогнозирования оттока клиентов с целью минимизации оттока. Было проведено сравнения разных методов борьбы с диспбалансом классов


| Метод | F1-score | ROC AUC | Accuracy | Recall | Precision |
| --- | --- | --- | --- | --- | --- |
| defolt | 0.574 | 0.856 | 0.860 | 0.464 | 0.753 |
| th-d | 0.611 | 0.768 | 0.826 | 0.671 | 0.561 |
| over_sample | 0.624 | 0.857 | 0.842 | 0.644 | 0.605 |
| os+th-d | 0.625 | 0.774 | 0.837 | 0.668 | 0.587 |
| under_sample | 0.595 | 0.858 | 0.792 | 0.749 | 0.494 |
| us+th-d | 0.611 | 0.765 | 0.830 | 0.654 | 0.573 |
| weight | 0.596 | 0.860 | 0.840 | 0.580 | 0.613 |
| w + Th-d | 0.613 | 0.771 | 0.826 | 0.678 | 0.560 |

- После объединения обучающей и валидационной выборок и повторного обучения модели на них,<br> на тестовой выборкес помощью подбора порога классификации достигнут результат по метрике F1- 0.637.

